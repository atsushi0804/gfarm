*** Gfarm system

Gfarm is a reference implementation of the Grid Datafarm architecture
designed for global petascale data-intensive computing.  It provides a
global parallel filesystem with online petascale storage, scalable I/O
bandwidth, and scalable parallel processing, and it can exploit local
I/O in a grid of clusters with tens of thousands of nodes.  Gfarm
parallel I/O APIs and commands provide a single filesystem image and
manipulate filesystem metadata consistently.  Fault tolerance and load
balancing are automatically managed by file duplication or
re-computation using a command history log.

For a detailed information about the Grid Datafarm architecture and
its preliminary performance evaluation, refer to the following paper.

[1] Osamu Tatebe, Youhei Morita, Satoshi Matsuoka, Noriyuki Soda,
    Satoshi Sekiguchi,
    "Grid Datafarm Architecture for Petascale Data Intensive Computing,"
    Proceedings of the 2nd IEEE/ACM International Symposium on Cluster
    Computing and the Grid (CCGrid 2002),
    IEEE, pp.102-110, 2002
    http://datafarm.apgrid.org/

========================================================================

*** Component of Gfarm system

Gfarm system consists of the following nodes

 - client node

  Terminal node for users.

 - filesystem node

  Filesystem node provides disks and CPUs for the Gfarm system.  On
  each filesystem node, the Gfarm filesystem daemon, called gfsd, is
  running to facilitate remote file operations with access control in
  the Gfarm filesystem as well as user authentication, file
  replication, fast invocation, node resource status monitoring, and
  control.

 - metadata server node

  Metadata server node manages Gfarm filesystem metadata and parallel
  process information.  On the metadata server node, the Gfarm
  filesystem metaserver, called gfmd, is running.

A file in the Gfarm filesystem is a large-scale file that is divided
into fragments or a ranked group of files, and distributed across the
disks of filesystem nodes, and which will be accessed in parallel.
The Gfarm filesystem is an extension of a striping parallel system in
that each file fragment has an arbitrary length and can be stored on
any node.

A file in the Gfarm filesystem, specified by a Gfarm filename or a
Gfarm URL such as gfarm:/path/name, is accessed using the Gfarm
parallel I/O library or Gfarm commands which provide a
single-filesystem image.

========================================================================

*** Structure of Gfarm software

Gfarm software consists of

 - libgfarm.a library

  A library that implements Gfarm APIs including Gfarm filesystem
  operations, parallel I/O extensions, parallel file transfer,
  file-affinity process scheduling.  Parallel I/O extensions provide
  new file views; index file view and local file view.

  A syscall-hook library, gfs_hook.o, is provided for porting legacy
  applications.  Linking with gfs_hook.o and libgfarm.a, the legacy
  applications can exploit the Gfarm filesystem.

 - gfmd - Gfarm metadata server

  gfmd is a Gfarm filesystem metadata server for accessing filesystem
  metadata of the Gfarm filesystem.  gfmd is needed to be running on a
  metadata server node in advance.

  In the current implementation, filesystem metadata is managed by an
  LDAP server, which is also to be running on, typically, a metadata
  server node.

 - gfsd - Gfarm filesystem daemon

  An I/O daemon for the Gfarm filesystem that is running on every
  filesystem node, which provides remote file operations with access
  control as well as user authentication, file replication, fast
  invocation, node resource status monitoring.

 - Gfarm command tools

  Gfarm command tools consists of filesystem commands like gfls, gfrm,
  gfwhere and gfrep, a filesystem node management tool like gfhost,
  file management tools like gfreg and gfexport, session key
  management tools like gfkey, and parallel process management tools
  like gfps, gfrun and gfmpirun_p4, which are located in the directory
  gftool/.

  In the gfptool/ directory, there are parallel Gfarm commands; gfcp
  for a parallel copy command, gfgrep for a parallel grep utility,
  gfwc for a parallel word-counts utility, etc.

 - Gfarm sample programs

  This distribution includes several sample programs.  gfimport_fixed
  and gfimport_text are examples for dividing and registering
  a file to the Gfarm filesystem, which  are located in the directory
  gftool/example.

========================================================================

*** Installation

This distribution is fully tested on Linux.  Building test is done on
NetBSD, Solaris.

To build the Gfarm system, OpenLDAP and OpenSSL libraries are
required.  To utilize the Grid Security Infrastructure (GSI) for
authentication method, GSSAPI library is needed.  Currently, GSSAPI
library provided by the Globus toolkit version 2 (GT2) is only
supported by the configure.  When building a gfs_hook_mpi.o
syscall-hook library for executing legacy MPI applications on the
Gfarm filesystem, and when building sample MPI applications in this
distribution, an MPI library is needed.

Here are the installation steps of the Gfarm system.

	% ./configure [options]
	% make
	% make install

In the following command options, it is necessary to specify at least
the --with-openldap option.

  --with-openldap=directory

  specifies an installation directory of the OpenLDAP library.

  --with-openssl=directory

  specifies an installation directory of the OpenSSL library.  Default
  directory is /usr.

  --with-mpi=directory

  specifies an installation directory of MPI to build sample MPI
  applications and a syscall-hook library for MPI applications.  If
  the directory is specified, ${directory}/bin/mpicc is used to
  compile MPI applications.  Otherwise, mpicc is used.  This is
  optional.

  --with-globus=directory

  specifies an installation directory of GT2 to utilize GSI
  authentication method.  When not specifying a directory,
  environment variable GLOBUS_LOCATION is used.  This is optional.

  --prefix=directory

  specifies a destination directory for installation.  Default is
  $HOME directory.  This is optional.

When you need to specify a compiler program explicitly, use the
environment variable CC.  This is an example using gcc.

	% env CC=gcc ./configure [options]

========================================================================

*** Initial configuration

This section describes an initial configuration by an administrator.

This section assumes the following setting.

 - Gfarm installation directory

	/usr/local/gfarm

 - OpenLDAP installation directory

	/usr/local/openldap

 - hostname of an LDAP server

	ldap.example.com

 - TCP port number of the LDAP server

	389

 - directory for configuration files of LDAP server

	/etc/gfarm-ldap

 - initial database file for LDAP database

	/etc/gfarm-ldap/initial.ldif

 - directory for LDAP database

	/var/gfarm-ldap

 - base distinguished name of LDAP

	dc=example,dc=com

	It is recommended to choose the base distinguish name by using
	each component of the fully qualified domain name (FQDN) as
	a right hand value of "dc=".

 - Gfarm spool directory on filesystem nodes

	/var/spool/gfarm

------------------------------------------------------------------------

** LDAP server

In the current distribution, an LDAP server manages the Gfarm
filesystem metadata.  This subsection describes the configuration for
the Gfarm filesystem metadata.

 - slapd.conf

This is a configuration file for an LDAP server included in the
OpenLDAP distribution.  Note that suffix and rootdn in this file
refer to the base distinguished name.

This is an example of /etc/gfarm-ldap/slapd.conf on ldap.example.com.
The path name of core.schema on line 5 depends on the installation of
the OpenLDAP.

----------------------------- BEGIN HERE -----------------------------
#
# See slapd.conf(5) for details on configuration options.
# This file should NOT be world readable.
#
include         /etc/openldap/schema/core.schema
include         /etc/gfarm-ldap/gfarm.schema

pidfile         /var/run/gfarm-slapd.pid
argsfile        /var/gfarm-ldap/slapd.args

# enable global write access for now. XXX
defaultaccess write

# unlimit search result
sizelimit 2000000000

#######################################################################
# ldbm database definitions
#######################################################################

database        ldbm

suffix          "dc=example, dc=com"
rootdn          "cn=root, dc=example, dc=com"

directory       /var/gfarm-ldap
rootpw          secret-ldap-password

# Indices to maintain
index	objectClass	eq

index	pathname	pres,eq
index	section		pres,eq
index	hostname	pres,eq
#
dbnosync
-------------------------------- END --------------------------------

 - gfarm.schema

This is a schema file for the Gfarm filesystem metadata used by
slapd.conf, which is located at /etc/gfarm-ldap/gfarm.schema on
ldap.example.com.  There is no need to modify.

----------------------------- BEGIN HERE -----------------------------
#
# OID Base is:
#	iso(1) org(3) dod(6) internet(1) private(4) enterprise(1) 
#		sra(13122) experimental(2) user(1) 
#			soda(2924) gfarm(100)
# i.e. gfarm schema OID base is 1.3.6.1.4.1.13122.2.1.2924.100
#
# gfarm schema:
#	1.3.6.1.4.1.13122.2.1.2924.100.1.x attribute syntax
#	1.3.6.1.4.1.13122.2.1.2924.100.2.x attribute type
#	1.3.6.1.4.1.13122.2.1.2924.100.3.x object class

# Attribute Type Definitions
# 1.3.6.1.4.1.13122.2.1.2924.100.2.x

attributetype ( 1.3.6.1.4.1.13122.2.1.2924.100.2.1 NAME 'hostname'
	EQUALITY caseIgnoreIA5Match
	SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 SINGLE-VALUE )
attributetype ( 1.3.6.1.4.1.13122.2.1.2924.100.2.2 NAME 'hostalias'
	EQUALITY caseIgnoreIA5Match
	SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 )
attributetype ( 1.3.6.1.4.1.13122.2.1.2924.100.2.3 NAME 'architecture'
	EQUALITY caseExactIA5Match
	SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 SINGLE-VALUE )
attributetype ( 1.3.6.1.4.1.13122.2.1.2924.100.2.4 NAME 'ncpu'
	EQUALITY caseExactIA5Match
	SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 SINGLE-VALUE )

attributetype ( 1.3.6.1.4.1.13122.2.1.2924.100.2.5 NAME 'pathname'
	EQUALITY caseExactIA5Match
	SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 SINGLE-VALUE )
attributetype ( 1.3.6.1.4.1.13122.2.1.2924.100.2.6 NAME 'mode'
	EQUALITY caseExactIA5Match
	SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 SINGLE-VALUE )
attributetype ( 1.3.6.1.4.1.13122.2.1.2924.100.2.7 NAME 'user'
	EQUALITY caseExactIA5Match
	SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 SINGLE-VALUE )
attributetype ( 1.3.6.1.4.1.13122.2.1.2924.100.2.8 NAME 'group'
	EQUALITY caseExactIA5Match
	SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 SINGLE-VALUE )
attributetype ( 1.3.6.1.4.1.13122.2.1.2924.100.2.9 NAME 'atimesec'
	EQUALITY caseExactIA5Match
	SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 SINGLE-VALUE )
attributetype ( 1.3.6.1.4.1.13122.2.1.2924.100.2.10 NAME 'atimensec'
	EQUALITY caseExactIA5Match
	SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 SINGLE-VALUE )
attributetype ( 1.3.6.1.4.1.13122.2.1.2924.100.2.11 NAME 'mtimesec'
	EQUALITY caseExactIA5Match
	SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 SINGLE-VALUE )
attributetype ( 1.3.6.1.4.1.13122.2.1.2924.100.2.12 NAME 'mtimensec'
	EQUALITY caseExactIA5Match
	SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 SINGLE-VALUE )
attributetype ( 1.3.6.1.4.1.13122.2.1.2924.100.2.13 NAME 'ctimesec'
	EQUALITY caseExactIA5Match
	SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 SINGLE-VALUE )
attributetype ( 1.3.6.1.4.1.13122.2.1.2924.100.2.14 NAME 'ctimensec'
	EQUALITY caseExactIA5Match
	SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 SINGLE-VALUE )
attributetype ( 1.3.6.1.4.1.13122.2.1.2924.100.2.15 NAME 'nsections'
	EQUALITY caseExactIA5Match
	SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 SINGLE-VALUE )

attributetype ( 1.3.6.1.4.1.13122.2.1.2924.100.2.16 NAME 'section'
	EQUALITY caseExactIA5Match
	SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 SINGLE-VALUE )
attributetype ( 1.3.6.1.4.1.13122.2.1.2924.100.2.17 NAME 'filesize'
	EQUALITY caseExactIA5Match
	SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 SINGLE-VALUE )
attributetype ( 1.3.6.1.4.1.13122.2.1.2924.100.2.18 NAME 'checksumType'
	EQUALITY caseExactIA5Match
	SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 SINGLE-VALUE )
attributetype ( 1.3.6.1.4.1.13122.2.1.2924.100.2.19 NAME 'checksum'
	EQUALITY caseExactIA5Match
	SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 SINGLE-VALUE )

# Object Class Definitions
# 1.3.6.1.4.1.13122.2.1.2924.100.3.x

objectclass ( 1.3.6.1.4.1.13122.2.1.2924.100.3.1
	NAME 'GFarmHost' SUP top STRUCTURAL
	MUST ( hostname $ architecture )
	MAY ( ncpu $ hostalias ) )

objectclass ( 1.3.6.1.4.1.13122.2.1.2924.100.3.2
	NAME 'GFarmPath' SUP top STRUCTURAL
	MUST ( pathname )
	MAY (	mode $ user $ group $
		atimesec $ atimensec $
		mtimesec $ mtimensec $
		ctimesec $ ctimensec $
		nsections ) )

objectclass ( 1.3.6.1.4.1.13122.2.1.2924.100.3.3
	NAME 'GFarmFileSection' SUP top STRUCTURAL
	MUST ( pathname $ section )
	MAY ( filesize $ checksumType $ checksum ) )

objectclass ( 1.3.6.1.4.1.13122.2.1.2924.100.3.4
	NAME 'GFarmFileSectionCopy' SUP top STRUCTURAL
	MUST ( pathname $ section $ hostname ) )
-------------------------------- END --------------------------------

 - Create the initial database file of filesystem metadata

Initial database should contain the root node information of LDAP,
which includes the base distinguished name specified by the "dn"
(distinguished name) attribute, and "top" specified by the
"objectclass" attribute.

This is a sample database file of /etc/gfarm-ldap/initial.ldif on
ldap.example.com.

----------------------------- BEGIN HERE -----------------------------
dn: dc=example, dc=com
objectclass: top

-------------------------------- END --------------------------------

 - Create an LDAP database

The 'slapadd' command creates an initial LDAP database.  The following
example shows how to create the initial LDAP database using the above
initial entries on ldap.example.com.

	% rm -f /var/gfarm-ldap/*
	% cd /etc/gfarm-ldap
	% /usr/local/openldap/sbin/slapadd -f slapd.conf -l initial.ldif

 - Execute an LDAP server

An LDAP server is invoked by the 'slapd' command.

	% cd /usr/local/openldap/libexec/
	% ./slapd -f /etc/gfarm-ldap/slapd.conf -h ldap://:389/

The -h option specifies a listening port number of the LDAP server.  A
sample start-up script can be found at package/<arch>/gfarm-slapd.
If you choose a port number less than 1024 like this example, you
have to do above with the root privilege.

 - Test the LDAP server

Try to execute the following commands.  If the same content as the
initial.ldif file is displayed, the LDAP server works fine.

In the case of the Bourne Shell:

	% host=ldap.example.com
	% port=389
	% basedn='dc=example, dc=com'
	% cd /usr/local/openldap/bin
	% ./ldapsearch -x -b "$basedn" -L -h $host -p $port '(objectclass=*)'

In the case of the csh:

	% set host=ldap.example.com
	% set port=389
	% set basedn='dc=example, dc=com'
	% cd /usr/local/openldap/bin
	% ./ldapsearch -x -b "$basedn" -L -h $host -p $port '(objectclass=*)'

------------------------------------------------------------------------

** ~/.gfarmrc

On your client node, create the configuration file ~/.gfarmrc.  Here
is an example.

----------------------------- BEGIN HERE -----------------------------
metadb_serverhost ldap.example.com
ldap_serverhost ldap.example.com
ldap_serverport 389
ldap_base_dn "dc=example, dc=com"
auth enable sharedsecret 163.220.31.0/24
auth enable gsi ALL
-------------------------------- END --------------------------------

** Register filesystem nodes

Every filesystem node need to be registered to the Gfarm metadata.
The 'gfhost -c' command is used to register the node information,
which includes hostname, hostalias, architecture, and ncpu;

% gfhost -c -a <architecture> [ -n <ncpu> ] <hostname> [ <hostalias> ... ]

  -- hostname

    fully qualified domain name (FQDN) of the host.

  -- hostalias

    If the host has multiple network interfaces that have different
    hostnames, these hostnames can be specified as hostname aliases by
    subsequent parameters of the hostname.  This is optional.

  -- architecture

    architecture name like sparc-sun-solaris, which is specified by
    the -a option.

  -- ncpu

    the number of cpus, which is specified by the -n option.  This is
    optional.

The followings are sample commands to register those information.

	% gfhost -c -a i386-redhat-linux linuxhost-1.example.com
	% gfhost -c -a i386-redhat-linux linuxhost-2.example.com
	% gfhost -c -a i386-redhat-linux linuxhost-3.example.com
	% gfhost -c -a i386-redhat-linux linuxhost-4.example.com
	% gfhost -c -a i386-debian-linux -n 2 linuxhost-5.example.com
	% gfhost -c -a i386-debian-linux -n 2 linuxhost-6.example.com
	% gfhost -c -a sparc-sun-solaris solarishost-1.example.com
	% gfhost -c -a sparc-sun-solaris solarishost-2.example.com
	% gfhost -c -a alpha-dec-osf osfhost-1.example.com
	% gfhost -c -a mips-sgi-irix -n 16 irixhost-1.example.com

You can confirm the filesystem node information by specifying the -D
option with the gfhost command:

	% gfhost -D
	i386-redhat-linux 1 linuxhost-1.example.com
	i386-redhat-linux 1 linuxhost-2.example.com
	i386-redhat-linux 1 linuxhost-3.example.com
	i386-redhat-linux 1 linuxhost-4.example.com
	i386-debian-linux 2 linuxhost-5.example.com
	i386-debian-linux 2 linuxhost-6.example.com
	sparc-sun-solaris 1 solarishost-1.example.com
	sparc-sun-solaris 1 solarishost-2.example.com
	alpha-dec-osf 1 osfhost-1.example.com
	mips-sgi-irix 16 irixhost-1.example.com

------------------------------------------------------------------------

** Create a gfsd spool directory on filesystem nodes

On each filesystem node, create a spool root directory
/var/spool/gfarm.  Moreover, under the spool root directory, create a
bin/ directory and every user directory, although user directories
will be automatically created by the 'gfrun' command described later.
The following example creates user directories for three users;
morita, tatebe, and soda.

	% su
	Password: 
	# sh
	# mkdir /var/spool/gfarm
	# chmod 1777 /var/spool/gfarm
	# mkdir /var/spool/gfarm/bin
	# chmod 1777 /var/spool/gfarm/bin
	# for u in morita tatebe soda; do
	>   mkdir /var/spool/gfarm/$u
	>   chown ${u} /var/spool/gfarm/$u
	> done
	# exit
	# exit
	% 

** /etc/gfarm.conf

Create /etc/gfarm.conf on every filesystem node and metadata server
nodes.  Here is an example of the configuration file.

----------------------------- BEGIN HERE -----------------------------
spool /var/spool/gfarm
metadb_serverhost ldap.example.com
ldap_serverhost ldap.example.com
ldap_serverport 389
ldap_base_dn "dc=example, dc=com"
auth enable sharedsecret 163.220.31.0/24
auth enable gsi ALL
-------------------------------- END --------------------------------

When filesystem nodes or metadata server nodes are used as a client
node, client programs read ~/.gfarmrc first if it exists, and then
read /etc/gfarm.conf.

** gfmd

On a metadata server node, execute gfmd with a root privilege.  Gfmd
reads the configuration file /etc/gfarm.conf described above.

	% su
	Password: 
	# gfmd

You can find a sample start-up script at package/<OS>/gfmd.  For
a testing purpose, gfmd can be executed as a non-privileged user
process with the -f option (see man gfmd).

To see whether gfmd is correctly executed or not, you can use the gfps
command as follows.  If gfmd is correctly invoked, gfps immediately
exits without any warning message.

	% gfps

** gfsd

On every filesystem node, execute gfsd with a root privilege.  Gfsd
reads the configuration file /etc/gfarm.conf described above.

	% gfsd

You can find a sample start-up script at package/<OS>/gfsd.  For
a testing purpose, gfsd can be executed as a non-privileged user
process with the -f option (see man gfsd).

To see whether gfsd is correctly executed or not, you can use the
gfhost command with the -l option as follows.  At the beginning of
each line, system load averages of the host are shown for the past 1,
5, and 15 minutes.

	% gfhost -l
	0.00/0.00/0.00 i386-redhat-linux 1 linuxhost-1.example.com
	0.00/0.00/0.00 i386-redhat-linux 1 linuxhost-2.example.com
	-.--/-.--/-.-- i386-redhat-linux 1 linuxhost-3.example.com
	0.00/0.00/0.00 i386-redhat-linux 1 linuxhost-4.example.com
	0.40/0.45/0.42 i386-debian-linux 2 linuxhost-5.example.com
	0.43/0.50/0.40 i386-debian-linux 2 linuxhost-6.example.com
	0.10/0.00/0.00 sparc-sun-solaris 1 solarishost-1.example.com
	x.xx/x.xx/x.xx sparc-sun-solaris 1 solarishost-2.example.com
	0.00/0.00/0.00 alpha-dec-osf 1 osfhost-1.example.com
	0.35/0.58/0.21 mips-sgi-irix 16 irixhost-1.example.com

In the above example, -.-- of linuxhost3.example.com shows there is no
gfsd listening to the specified port on the machine.  x.xx of
solarishost-2.example.com shows there is no route to the machine.

** Register Gfarm parallel commands

Register Gfarm parallel commands like a parallel file copy command and
a parallel grep command to the Gfarm filesystem on a filesystem node
of every architecture.

	% make gfregister

All parallel commands will be registered in the gfarm:/bin directory.

	% gfls -l gfarm:/bin
	-rwxr-xr-x tatebe   *            404988 Feb  7 01:30 gfcombine
	-rwxr-xr-x tatebe   *            479056 Feb  7 01:30 gfcombine_hook
	-rwxr-xr-x tatebe   *            404133 Feb  7 01:30 gfcp
	-rwxr-xr-x tatebe   *            478109 Feb  7 01:30 gfcp_hook
	-rwxr-xr-x tatebe   *            406474 Feb  7 01:30 gfgrep
	-rwxr-xr-x tatebe   *            423342 Feb  7 01:44 gfreg
	-rwxr-xr-x tatebe   *            423255 Feb  7 01:30 gfsplck

You can check which architecture of a binary program is registered
using the gfwhere command.

	% gfwhere gfarm:/bin/gfcp

========================================================================

*** Examples

This section describes execution examples.

** Sign on

Currently, we support two authentication methods; a shared secret key
and the Grid Security Infrastructure.  You can select either method by
the configuration file; /etc/gfarm.conf or ~/.gfarmrc.

*** Shared secret key

This authentication method basically assumes a trusted environment
such that every node shares a home directory.  A shared secret key is
automatically created if it does not exist or has been expired, which
can be accessed by every node in the shared home directory.  There is
no need to sign on explicitly.

However, in a global environment or even a local cluster environment
that does not share the home directory, the shared secret key should
be securely distributed by users explicitly.  First, create a session
key, ~/.gfarm_shared_key, by gfkey command.

	% gfkey -c

Then, copy the key securely to the home directory on all nodes
including filesystem nodes, a metadata server node, and client nodes
usually by scp.  Note that this key will be expired after 24 hours.

*** Grid security infrastructure

This authentication method requires a user certificate and host
certificates for every filesystem node and a metadata server.
Moreover, your entry should be listed in a grid map file
/etc/grid-security/grid-mapfile on every node.

Then, create a user proxy certificate.

	% grid-proxy-init

** Execute sample programs

This subsection shows several execution examples of sample programs.

 - Importing a text file

  Gfimport_text is a sample program for dividing a text file to file
  fragments by the line and registering it to the Gfarm filesystem.

	% gfhost | gfimport_text -H - -o gfarm:test.txt textfile

  In this example, textfile in a local filesystem is divided to file
  fragments which will be stored on currently available filesystem
  nodes listed by the gfhost command.  Using the gfwhere command, you
  can see which filesystem node each file fragment is stored on.

	% gfwhere gfarm:test.txt

  Also, you can browse a directory using the gfls command.

	% gfls -l

  The gfexport command outputs a Gfarm file to the standard output.
  Using this, you can check whether gfimport_text correctly copies the
  "textfile" to the "gfarm:test.txt" in the Gfarm filesystem.

	% gfexport gfarm:test.txt | diff -c - textfile

 - Importing a fixed-size record file

	% gfhost | gfimport_fixed -H - -o gfarm:test.bin \
                         -l 100 fixed-size-record-file

  You can check whether gfimport_fixed correctly copies the
  "fixed-size-record-file" to the "gfarm:test.bin" in the Gfarm
  filesystem.

	% gfexport gfarm:test.bin | cmp - fixed-size-record-file

 - Importing a group of files

  When there are several files that are better to be managed as a
  ranked group of files, they can be registered to the Gfarm
  filesystem as a Gfarm file.  The following example shows ten files
  from file01 to file10 will be imported to a gfarm:file.

	% gfreg -I 0 -N 10 [ -h filesystem node ] file01 gfarm:file
	% gfreg -I 1 -N 10 [ -h filesystem node ] file02 gfarm:file
	% ...
	% gfreg -I 9 -N 10 [ -h filesystem node ] file10 gfarm:file

  The -h option should be specified when gfreg is executed not on a
  filesystem node.

 - gfgrep - parallel grep

  At first, you should check where the gfgrep program is already
  registered in the Gfarm filesystem.

	% gfls -l gfarm:/bin/gfgrep

  If not, you can register by yourself using the gfreg command, or
  'make gfregister' on a filesystem node.

	% gfreg /usr/local/gfarm/bin/gfgrep gfarm:/bin/gfgrep

  When you would like to register a binary program not on a filesystem
  node, the architecture name should be specified with the -a option.

  The gfrun command executes a parallel command on filesystem nodes
  with file-affinity scheduling.

	% gfrun -G gfarm:text.txt gfarm:gfgrep -o gfarm:gfgrep.out \
		regexp gfarm:test.txt

  You can check the result to compare the following outputs.

	% gfexport gfarm:gfgrep.out
	% grep regexp textfile

 - gfwc - parallel word counts

  When gfarm:/bin/gfwc is not registered, register it as follows.

	% gfreg /usr/local/gfarm/bin/gfwc gfarm:/bin/gfwc

  Since gfwc is an MPI application, it is executed using gfmpirun_p4.

	% gfmpirun_p4 gfarm:/bin/gfwc gfarm:test.txt

  You can check the result.

	% wc test.txt

$Id$
